[{
    "title": "LLVM 雜記",
    "date": "",
    "description": "一些有關 LLVM 的小小筆記",
    "body": "簡介 算是在研究 LLVM 時，一邊學習一邊踩坑的小筆記，所以有點雜亂，之後有機會再好好整理。學習過程主要是希望可以用 Clang 編譯 CUDA code，並且利用 LLVM IR 對 Host side 的 Code 做一些變化。最一開始從網路上的一個 LLVM Project 開始 Trace Code，並且一邊修改一邊嘗試。\n LLVM CUDA OPENTUNER tags: CS Relevent Link nvcc-llvm-ir\nCUDAAdvisor\nDifferent Version Compatibility\nDynaMap\nGpuDrano Dynamic Analysis\nGPU Drano Static Analysis\nEnabling on-the-fly manipulations with LLVM IR code of CUDA sources\nLLVM Pass Slide (這個好像很讚)\nGood Intro to LLVM IR Pass\n一些之乎大神\n這個在講怎麼編譯\n在講 NVVM 讚\n這邊講了一下 CUDA 的一些限制，還不錯\nLLVM字典\n RAUW Replace All Uses With. Implement the replacement of one Value with another by iterating over its def/use chain and fixing up all of the pointers to point to the new value.  LLVM Install Build from source  Clone and version specified git clone https://github.com/llvm/llvm-project.git -b llvmorg-10.0.0 Follow Clang/LLVM Build clang and llvm cmake command cmake -DCMAKE_INSTALL_PREFIX=/usr/bin -DCMAKE_BUILD_TYPE=Release -D_GLIBCXX_USE_CXX11_ABI=0 -DLLVM_ENABLE_PROJECTS=clang -G \u0026quot;Unix Makefiles\u0026quot; ../llvm  Link with full path sudo ln -sf ~/llvm-project/build/bin/* /usr/bin/  Error while compilng LLVM $ -- Performing Test HAVE_GNU_POSIX_REGEX -- failed to compile 好像沒差???\n LLVM IR to executable 感覺還滿詳細的教學 CUDA 學習系列網址 Makefile\nssh -L 5906:127.0.0.1:5906 -N -l yuweitt 140.112.42.182 -p 607\nCompilation breakdown 這邊基本上就是利用 verbose 的 Flag，把整個 Flow 都印出來。但是有一個問題，就是我找不到 cicc，在 CUDA 的官方文件中，這個基本上是要用來完成 device code to ptx 的部分。 問題是在 cuda 的 binary 裡面並沒有看到這個 executable，所以也沒有辦法編譯。不過其實好像也不用用到 cicc，反正他只是要把 fatbinary 編出來，用 $fatbinary 就可以把他編出來了。\n➜ vectorAdd nvcc -dryrun --include-path=\u0026#34;../../common/inc\u0026#34; vectorAdd.cu $ gcc \u0026#34;vectorAdd.cu\u0026#34; \u0026gt; \u0026#34;8_vectorAdd.cpp1.ii\u0026#34; $ cicc -arch compute_30 --include_file_name \u0026#34;2_vectorAdd.fatbin.c\u0026#34; --orig_src_file_name \u0026#34;vectorAdd.cu\u0026#34; --gen_c_file_name \u0026#34;5_vectorAdd.cudafe1.c\u0026#34; --stub_file_name \u0026#34;5_vectorAdd.cudafe1.stub.c\u0026#34; \u0026#34;8_vectorAdd.cpp1.ii\u0026#34; -o \u0026#34;5_vectorAdd.ptx\u0026#34; $ ptxas -arch=sm_30 \u0026#34;5_vectorAdd.ptx\u0026#34; -o \u0026#34;9_vectorAdd.sm_30.cubin\u0026#34; $ fatbinary --create=\u0026#34;2_vectorAdd.fatbin\u0026#34; \u0026#34;--image=profile=sm_30,file=9_vectorAdd.sm_30.cubin\u0026#34; \u0026#34;--image=profile=compute_30,file=5_vectorAdd.ptx\u0026#34; --embedded-fatbin=\u0026#34;2_vectorAdd.fatbin.c\u0026#34; $ gcc \u0026#34;vectorAdd.cu\u0026#34; \u0026gt; \u0026#34;4_vectorAdd.cpp4.ii\u0026#34; $ cudafe++ --gen_c_file_name \u0026#34;5_vectorAdd.cudafe1.cpp\u0026#34; --stub_file_name \u0026#34;5_vectorAdd.cudafe1.stub.c\u0026#34; \u0026#34;4_vectorAdd.cpp4.ii\u0026#34; $ gcc -o \u0026#34;10_vectorAdd.o\u0026#34; \u0026#34;5_vectorAdd.cudafe1.cpp\u0026#34; $ nvlink --register-link-binaries=\u0026#34;6_a_dlink.reg.c\u0026#34; \u0026#34;10_vectorAdd.o\u0026#34; -o \u0026#34;11_a_dlink.sm_30.cubin\u0026#34; $ fatbinary --create=\u0026#34;7_a_dlink.fatbin\u0026#34; -link \u0026#34;--image=profile=sm_30,file=11_a_dlink.sm_30.cubin\u0026#34; --embedded-fatbin=\u0026#34;7_a_dlink.fatbin.c\u0026#34; $ gcc -DFATBINFILE=\u0026#34;\\\u0026#34;7_a_dlink.fatbin.c\\\u0026#34;\u0026#34; DREGISTERLINKBINARYFILE=\u0026#34;\\\u0026#34;6_a_dlink.reg.c\\\u0026#34;\u0026#34; -o \u0026#34;12_a_dlink.o\u0026#34; \u0026#34;/usr/local/cuda/bin/crt/link.stub\u0026#34; $ g++ -o \u0026#34;a.out\u0026#34; --start-group \u0026#34;12_a_dlink.o\u0026#34; \u0026#34;10_vectorAdd.o\u0026#34; Compilation command from clang verbose Link 單純利用 clang++ um.cu -o um --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread 編譯的時候，如果下 -v 的 verbose Command 可以看到他實際跑了哪些指令。在原本的指令中，沒有儲存 Intermediate，直接生成 object file，但是只要把原本的 -emib-obj 改成 -emit-llvm-bc，就可以了。然後 bc 一樣可以直接跑 LLVM 的 pass，最後可以編譯成功。\n跑 pass 的指令 opt -S -load /home/yuweitt/llvm-project/build/lib/CUDAMemPass.so -cudamem host.ll -o hosti.ll\nMakefile from CUDAAdvisor Link 從 CUDAAdvisor 找到他們的 Makefile，我改成我需要的形狀，但是目前也還不能編譯。\nCUDAAdvisor 這邊走的是一個 clang++ cc1 風格，解釋大概長這樣\nThe Clang compiler front-end has several additional Clang specific features which are not exposed through the GCC compatibility driver interface. The -cc1 argument indicates that the compiler front-end is to be used, and not the driver. The clang -cc1 functionality implements the core compiler functionality.\n他下了很多不同的 flag，這部分跟 clang++ 直接把 cuda file 編譯成 executable 的過程一樣，也有調用到 clang++ -cc1。這邊編譯遇到的問題是 undeclared identifier，這個感覺比較麻煩，因為明明有下-fcuda-include-gpubinary device.fatbin 這條，所以照理說會連結到已經編好的 cuda fatbinary 才對，這部分還要再研究一下。\num.cu:46:8: error: use of undeclared identifier cudaConfigureCall Myadd\u0026lt;\u0026lt;\u0026lt;numBlocks, blockSize\u0026gt;\u0026gt;\u0026gt;(N, x, y); ^ 1 error generated when compiling for host. CUA_Makefile:39: recipe for target \u0026#39;host.bc\u0026#39; failed My Makefile Link\nMakefile from Stackoverflow Link 這個 Makefile 是從 Stackoverflow 上面來的，該作者用的是 Power PC ??，但反正應該改成 x86_64 就可以了，只是不知道為什麼還是不能跑。\n這邊最後 link 部分是直接調用 NVIDIA 的 nvcc，反正無腦給他跑應該就會自己去啟動 driver，就沒有用到上面的 clang++ -cc1，不過現在問題就是遇到這個 error，找不到-lc++，我上網查也找不到太到-lc++這個 flag，可以想見它就是要 load c++ library，但是這樣下 flag 真的是對的嗎? 作者是說他可以跑，我再試試看。\nnvcc um.o um_dlink.o -o um -arch=sm_61 -lc++ /usr/bin/ld: cannot find -lc++ collect2: error: ld returned 1 exit status 如果把那個 flag 拿掉會變這樣，GG\nnvcc um.o um_dlink.o -o um -arch=sm_61 /usr/bin/ld: um.o: relocation R_X86_64_32 against symbol `_Z5MyaddiPfS_\u0026#39; can not be used when making a PIE object; recompile with -fPIC /usr/bin/ld: final link failed: Nonrepresentable section on output collect2: error: ld returned 1 exit status My github Makefile link\nCUDA 路徑  LD_LIBRARY_PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local CUDA_HOME export CUDA_HOME=/usr/local/cuda export PATH=$PATH:/usr/local/cuda/bin  CUDA 編譯學習   clang++ -c The -c flag is used to tell the compiler you don\u0026rsquo;t want to build a program (link together into an executable), just compile this particular file into an object file - typically producing a file called something.o or something.obj\n  -E Stop after the preprocessing stage; do not run the compiler proper. The output is in the form of preprocessed source code, which is sent to the standard output.\n  Stpes\n  # This generate um-cuda-nvptx64-nvidia-cuda-sm_61.s and um.s $ clang++ -S um.cu --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread # This generate cuda device object file $ ptxas -m64 -O0 --gpu-name sm_61 --output-file um-cuda.o um-cuda-nvptx64-nvidia-cuda-sm_61.s # This generate cuda fatbinary $ fatbinary -64 --create um-cuda.fatbin --image=profile=sm_61,file=um-cuda.o --image=profile=compute_61,file=um-cuda-nvptx64-nvidia-cuda-sm_61.s $ llc \u0026lt; new.ll \u0026gt; new.s CUDA 的 Comiple Flow\n這個是 NVIDIA 的官方文件，講述 NVVM 還有 LLVM IR 的東西。\n NVVM IR 和 LLVM IR Technically speaking, NVVM IR is LLVM IR with a set of rules, restrictions, and conventions, plus a set of supported intrinsic functions. A program specified in NVVM IR is always a legal LLVM program. A legal LLVM program may not be a legal NVVM program.  Command clang++ um.cu -o um --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread\nclang++ --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lcuda -lrt -pthread -lcudart um.o um-cuda.ptx.o -o um 會有這個 error，加入 -lcudart 就可以解決沒有 reference 的問題，但是 incompatible 還是沒有辦法解決。\n How to write a LLVM Pass Example pass \u0026ldquo;Hello.cpp\u0026rdquo; under ~/llvm-project/llvm/lib/Transformation/. The correspond .so file will be genereated under ~/llvm-project/build/lib/ after rebuild.\n$clang `llvm-config --cxxflags` -Wl,-znodelete \\ -fno-rtti -fPIC -shared cuda_mem.cpp \\ -o CUDAMem.so `llvm-config --ldflags`  Run my LLVM pass $ opt -load lib/CUDAMemPass.so -cudamem \u0026lt; ~/cuda/um/um.ll \u0026gt; /dev/null  Understanding DynaMap 這邊先來看一下 Module, Function, Basic Block 的關係  LLVMContext Important class for using LLVM in a threaded context Manage core \u0026ldquo;global\u0026rdquo; data of LLVM\u0026rsquo;s core infrastructure, including the type and constant uniquing tables  Peek into um.ll We see cudaMallocManaged\nModule.h iterator begin() { return FunctionList.begin(); } named_metadata_iterator named_metadata_begin() { return NamedMDList.begin(); } Get MDnode from module for (auto named_meta = module-\u0026gt;named_metadata_begin(); named_meta != module-\u0026gt;named_metadata_end(); named_meta++) for (auto op = named_meta-\u0026gt;op_begin(); op != named_meta-\u0026gt;op_end(); op++) // This is not working NamedMDListType (ilist\u0026lt;NamedMDNode\u0026gt;) Define in llvm/Module.h ilist\u0026lt;T\u0026gt;是LLVM中自定義的其中一種 Container，其實就和 STL 的 List 很像，但是做了一些改變以符合 LLVM 內部需求。詳細請見 User Manual 所以總的來說，他就是一個 List 裡面存一堆 NamedMDNode\nNamedMDNode A tuple of MDNodes. Despite its name, a NamedMDNode isn\u0026rsquo;t itself an MDNode. It is illegal for a NamedMDNode to appear as an operand of an MDNode. 這邊暫時不太懂他在幹嘛 :::info A NamedMDNode looks like this: !named = !{!0, !1} An MDNode looks like this: !0 = !{!1, i32 0, i32* @global} :::\nNamedMDNode *node = module-\u0026gt;getNamedMetadata(MetaName); // 大部分的操作好像都長這樣，可是我要怎麼拿到 MDNode呢 MDNode Metadata nodes can be uniqued, like constants, or distinct. Temporary metadata nodes (with full support for RAUW) can be used to delay uniquing until forward references are known. The basic metadata node is an MDTuple. 要怎麼使用 MDNode 呢，請看 MDNode\nMDNode *getLoopID() const; // Return the llvm.loop loop id metadata node for this loop if it is present. Metadata Root of the metadata hierarchy. This is a root class for typeless data in the IR. 也許我們把 Metadata 搞懂，就可以知道這一系列在幹嘛 Here comes the explaination -\u0026gt; link :::info\n One example application of metadata is source-level debug information.  class Metadata { //這三個不知道在幹嘛 enum StorageType { Uniqued, Distinct, Temporary }; unsigned char Storage : 7; unsigned char SubclassData1 : 1; unsigned short SubclassData16 = 0; unsigned SubclassData32 = 0; IRBuilder Literally, build LLVM IR.\nProblem 好像要先人工分析一些 IR 的資訊，才知道 Pass 要怎麼寫，所以可能要先看懂一些 Label (Function 的)，這樣才知道 Pass 要寫啥。\n什麼時候用 Metadata，Functin Name???\nNaming convention ???\n  Compile Cuda with clang Generate bc and opt pass clang -emit-llvm um.cu -c -o hello.bc\nCommand clang++ um.cu -o um --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread -save-temps\n cudart : cuda run time dl : This is the interface to the dynamic loader, which provides a client program with ability to do things such as explicitly load other libraries, lookup symbols within, etc.  cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=clang -G \u0026quot;Unix Makefiles\u0026quot; ../llvm \nHow to specify compute capability What is cui file ??? with cuda docker and clang-12\n\u0026lt;built-in\u0026gt;:1:10: fatal error: \u0026#39;__clang_cuda_runtime_wrapper.h\u0026#39; file not found #include \u0026#34;__clang_cuda_runtime_wrapper.h\u0026#34; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1 error generated when compiling for sm_62. Bad, docker seems to be the root of devil.\ngpucc: An Open-Source GPGPU Compiler\nGPU Compute Capability\n llc : The llc command compiles LLVM source inputs into assembly language for a specified architecture. -g flag : Generate complete debug info.    Manipualte CUDA UM Advanced Advice __host__ ​cudaError_t cudaMemAdvise \\ ( const void* devPtr, size_t count,\\ cudaMemoryAdvise advice, int device ) 所以會用到的值應該是 1、3、5 這三個。 NVIDIA Reference\n Default cudaMemAdviseSetReadMostly cudaMemAdviseSetPreferredLocation cudaMemAdviseSetAccessedBy   cudaMemAdvise(a, Size∗Size∗sizeof(float), cudaMemAdviseSetReadMostly, 0)\nIn LLVM IR Compile 出來會變成\ndeclare dso_local i32 @cudaMemAdvise(i8*, i64, i32, i32) #1 // 這個我有 %156 = load %struct.XYZ*, %struct.XYZ** %26, align 8 %157 = bitcast %struct.XYZ* %156 to i8* // %158 = load i32, i32* %19, align 4 %159 = sext i32 %158 to i64 %160 = invoke i32 @cudaMemAdvise(i8* %157, i64 %159, i32 1, i32 0) to label %161 unwind label %137 我插的，但是不能跑，會有 cuda error\ndeclare dso_local i32 @cudaMemAdvise(i8*, i64, i32, i32) %72 = load %struct.XYZ*, %struct.XYZ** %26, align 8 %73 = bitcast %struct.XYZ* %72 to i8* %74 = call i32 @cudaMemAdvise(i8* %73, i64 4096, i32 0, i32 0) Distance = 5\n265: ; preds = %261 %266 = getelementptr inbounds %struct.Params, %struct.Params* %11, i32 0, i32 1 %267 = load i32, i32* %266, align 4 %268 = getelementptr inbounds %struct.Params, %struct.Params* %11, i32 0, i32 1 %269 = load i32, i32* %268, align 4 %270 = mul nsw i32 %267, %269 %271 = load i32, i32* %35, align 4 %272 = icmp sle i32 %270, %271 br i1 %272, label %273, label %278 273: ; preds = %265 %274 = load %struct.XYZ*, %struct.XYZ** %26, align 8 %275 = bitcast %struct.XYZ* %274 to i8* %276 = call i32 @cudaMemPrefetchAsync(i8* %275, i64 512, i32 0, %struct.CUstream_st* null) %277 = call i32 @cudaMemAdvise(i8* %275, i64 512, i32 0, i32 0) br label %278  Manipulate CUDA Prefetch LLVM Manual Book\n因為我要放進去一個 Null Pointer，首先我先想辦法抓到 Struct 的 Type 結果我發現 LLVM 有很多 Type 這邊可以看到，StructType 就是其中之一，而其中就有 static function 可以根據你的 struct Name 拿到相對應的 Struct Type。\n這邊要注意的一點，就是我用的是 LLVM 10.0，而現在最新版的 Docutment 已經到 LLVM 14.0，最新版的 API 長這樣，基本上很易用，你只要把 Struct 的字串跟 Context 一起丟進去就可以了。\nstatic StructType * StructType::getTypeByName (LLVMContext \u0026amp;C, StringRef Name) 但是 LLVM 10.0的不行，10.0 的長這樣，而且是定義在 Module 的 class 裡面\nStructType* Module::getTypeByName (StringRef Name) const 至於要找之前的 Document 的話，我是打 LLVM 10.0 Doxygen，然後去下載他的 Docs，連結大概會長這樣，然後再去下載裡面的 llvm doxygen，解壓縮後就會有一堆 HTML 可以看。\n整體來說會長這樣\nStructType* CUstream_struct = module-\u0026gt;getTypeByName(\u0026#34;struct.CUstream_st\u0026#34;); // Check not null if(CUstream_struct) errs() \u0026lt;\u0026lt; \u0026#34;\\t CUstream struct : \u0026#34; \u0026lt;\u0026lt; CUstream_struct-\u0026gt;getStructName().str() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // Create null pointer Constant* CU_stream = ConstantStruct::getNullValue(CUstream_struct); 但是目前他的 IR 出來不是 Null，而是 Zero Initializer，感覺有鬼，哭啊。\n有一個想法是，先轉成 PointerType，然後再用Constant* ConstantPointerNull::get(PointerType) 這個函數拿到 null struct Pointer。但是很顯然我用dyn_cast的時候就出事了，轉出來是 nullptr。具體來說是這樣，還在研究。\nStructType* CUstream_struct = module-\u0026gt;getTypeByName(\u0026#34;struct.CUstream_st\u0026#34;); PointerType* CUstream_pointer = dyn_cast\u0026lt;PointerType\u0026gt;(CUstream_struct); // 這邊就不會 Print 東西出來了 if(CUstream_pointer) errs() \u0026lt;\u0026lt; \u0026#34;\\t CUstream pointer : \u0026#34; \u0026lt;\u0026lt; CUstream_pointer-\u0026gt;getElementType()-\u0026gt;getStructName().str() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // Segmentation Fault ConstantPointerNull* CU_stream_null = ConstantPointerNull::get(CUstream_pointer); 然後我上 StackOverflow 上面問，沒有人要裡我，哭啊 結果後來發現其實很簡單，不用 Cast 過去，PointerType Class 本身就有 static PointerType* get (Type *ElementType, unsigned AddressSpace)，所以 OK 的。 結論 - Nonintializer 的確不行\nStructType* CUstream_struct = module-\u0026gt;getTypeByName(\u0026#34;struct.CUstream_st\u0026#34;); ConstantPointerNull* CU_stream_null = ConstantPointerNull::get(PointerType::get(CUstream_struct, 0)); // 直接 bitcast Value* ir_ptr = builder.CreateBitCast(val, Type::getInt8PtrTy(context)); // Generate cuda prefetch instruction CallInst *MI = builder.CreateCall(cuda_prefetch_func, args); 愛情你比我想的閣較偉大 LLVM比我想的閣較複雜@@\n遇到的問題 現在 opt 跑完 Pass ，但是 IR 沒有改變，不知道是不是 opt 的用法\nInstruction does not dominate all uses (用第一個 Instruction 的話) Basic Block in function \u0026lsquo;main\u0026rsquo; does not have terminator! (用 BasicBlock 的話) Instruction referencing instruction not embedded in a basic block! (用 Context 的話)\n結論 排除以上困難，已經可以插入了 Prefetch，用 diff 看兩個 .ll 檔案 跑的指令 : opt -S -load lib/CUDAMemPass.so -cudamem ~/cuda/um/um.ll -o ~/cuda/um/new.ll \n Maybe relevent Paper\n現在遇到的一些困難是\n 這些 register 要怎麼拿到 ?? 還是要自己 Create ?? 我的 Function Callee 要放什麼 ?? 我怎麼知道有哪些 address 是要 prefetch 的 我想要知道之前 Prefetching 都是怎麼做的，利用Emulation ?? 還是 Cuda 我在 Auto-tune 的時候，是不是應該加上一些 Heuristic，還是完全自動，會不會無法收斂 GPU Page 有哪些東西可以改動，可是 Prefetch 是不是就會跟 Page Replacement 難以獨立 如果是會互相影響，是不是 Focus 一個做就好 ?? Granularity 要怎麼設會比較好?? 不同的 Optimization 之間，要一起做嗎???  想法\n 我可以知道 cudaMallocManage，那我應該就可以操控?? 我可以知道 Launch，那我也可以操控  看了一下 DynaDrano 以及其他的方法，大部分都是會寫 cu 的 Code，然後利用 LLVM Pass 把 Instrument 插進去。\n這個是從 CUDA 的 PTX 官方 Manual 上面拿下來的\n圖片太大了，有點礙眼，要看自己點進去\nCUDA Prefetch API\ncudaMemPrefetchAsync in LLVM IR 我現在可以拿到 Prefetch 的 Declaration 了 但是參數可能是一個問題\n目前可以做到這樣\n// %9 = alloca float*, align 8 // %16 = bitcast float** %9 to i8** // %20 = load i8*, i8** %16, align 8, !tbaa !7 // %21 = call i32 @cudaMemPrefetchAsync(i8* %20, i64 4096, i32 0, %struct.CUstream_st* null) IntegerType* int_type32 = IntegerType::get(context, 32); IntegerType* int_type64 = IntegerType::get(context, 64); ConstantInt* device_id = ConstantInt::get(int_type32, 0, false); ConstantInt* alloca_size = ConstantInt::get(int_type64, 4096, false); Value* args[] = {alloca_size, device_id}; builder.CreateCall(cuda_prefetch_func, args); 但是我要想辦法\n 生出 x 的位置 生出 struct.CUstream_st 的 null pointer  圖片\nWhat Next ???\n先看每個 Instruction 可以幹嘛\nfor (BasicBlock \u0026amp;BB : F) { for (Instruction \u0026amp;inst : BB) { if(inst.getOpcode() == Instruction::Call || inst.getOpcode() == Instruction::Invoke) { // errs() \u0026lt;\u0026lt; \u0026#34;\\\\n callinst =\u0026gt; \u0026#34; \u0026lt;\u0026lt; inst \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; // Instruction* I = \u0026amp;(inst); // errs() \u0026lt;\u0026lt; \u0026#34;\\\\n callinst =\u0026gt; \u0026#34; \u0026lt;\u0026lt; inst.getOpcodeName() \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; if (isa\u0026lt;CallInst\u0026gt;(\u0026amp;inst)) { Function *func = cast\u0026lt;CallInst\u0026gt;(\u0026amp;inst)-\u0026gt;getCalledFunction(); val = cast\u0026lt;CallInst\u0026gt;(\u0026amp;inst)-\u0026gt;getArgOperand(0); if(func) { StringRef fname = func-\u0026gt;getName(); if(fname == \u0026#34;cudaMallocManaged\u0026#34;) { errs() \u0026lt;\u0026lt; \u0026#34;\\\\t Function Name : \u0026#34; \u0026lt;\u0026lt; fname \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; errs() \u0026lt;\u0026lt; \u0026#34;\\\\n callinst =\u0026gt; \u0026#34; \u0026lt;\u0026lt; inst \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; } } } } } } 什麼是 LLVM Instrinsic ??? Intrinsic函數是編譯器內建的函數，由編譯器提供，類似於內聯函數。但與內聯函數不同的是，因為Intrinsic函數是編譯器提供，而編譯器與硬件架構聯繫緊密，因此編譯器知道如何利用硬件能力以最優的方式實現這些功能\n研究一下其他人的 Call 都做了哪些事情 Tutorial 好像應該先 Initialize Load\nLoadInst *Load2 = Builder.CreateLoad(IntegerType::getInt32Ty(CTX), Var); Value *Inc2 = Builder.CreateAdd(Builder.getInt32(1), Load2); Builder.CreateStore(Inc2, Var); 別人的研究呢 ?? XPlacer 用的是 Rose Source to source 的方式改動，但以 Instrumentation 來說，我覺得根本就是差不多的東西。\nIn contrast to CudaAdvisor, XPlacer instruments source code. On one side, instrumented binary code typically runs faster because the instrumentation can be added to an optimized binary, whereas source-level construmentation often poses an obstacle to compile-time code optimization. On the other side, instrumenting source code offers better portability across CUDA versions and is easier to understand for programmers not familiar with low-level details. XPlacer’s function level instrumentation can be more easily customized through pragmas\nLLVM Loop Prefetch Scalar Evolution（SCEV）是編譯器中對於變量進行分析的一個非常有用並且強大的 Library，當然通常情況下只是對於Loop 中 int類型的變量進行分析。本文主要是介紹Scalar Evolution在LLVM中的使用。\nSCEV是LLVM中一個很重要的analysis pass。所謂的analysis pass就是這個pass只是做分析工作，並不會修改 IR Code。很多重要的優化 pass 都有使用SCEV的結果，比如說循環變量簡化（IndVars）， Loop Strength Reduce(LSR)，（Vectorizer）。 Ref\n",
    "ref": "/blog/llvm/"
  },{
    "title": "攝影。初",
    "date": "",
    "description": "第一次，被親手按下快門的照片，深深的驚豔",
    "body": "如果說哪件事情，深深改變了我的生活，那毫無疑問的，就是攝影\n",
    "ref": "/blog/conver/"
  },{
    "title": "哈爾濱驚魂記",
    "date": "",
    "description": "帶著貓咪的好奇心，單眼相機的一隻眼睛，踏上一個人的旅程，居然在虎口前驚險逃出??",
    "body": "越想越不對勁 Intro  2018年暑假的時候，來到了哈爾濱交換\n  那天，是八月底，回台灣前的兩天\n一直嚮往可以去爬長白山或是黃山，最後卻未果\n失望無奈之下，在那天小夥伴們還未甦醒之時\n獨自一人搭著地鐵在哈爾濱的市區亂晃\n prologue 事件發生在哈爾濱地鐵博物館站，秋林百貨附近，某個人來人往的十字路口。這個十字路口有點大，十字路口的每一個角落都有一棟百貨公司。由於人生地不熟，就在人來人往，川流不息的四個百貨公司角落亂晃。 當我顧著拍照的時候，一不小心一腳踩進一坑水裡面。 一個大媽在我踩到水之前提醒我小心有水坑(雖然我還是踩進去了)，我還想說哇人這麼好 ，還會關心路人。\n接著他就開始講話了：\n帥哥，我們現在有一個活動，可以體驗皮膚保養品的活動，因為我們現在在促銷階段，也是免費的，我就是負責這一方面，所以如果你來的話也可以幫我達成一點業績。\n大意大概是這樣，可能他那時候講的比較委婉。一來我是那種喜歡聽別人講廢話的人，常 常跟路上傳教的人講話，二來想說百貨公司都是很明亮開闊的空間，應該只是一下下可能拿個宣傳就沒事了。\n所以，我就答應他了。\n白癡\n然後他看我說好，就說要帶我走去他們的專櫃，還一直跟我聊一些什麼你是哪裡人啊，如 果之後你覺得好用再幫我們推銷一下啊之類的。一直到走進大樓之後我才開始發覺好像有點怪怪的。\n進去的大樓完全不是百貨公司，而比較像是以前補習班的那種大樓，一樓進去只有電梯， 而且都暗暗的，有點破破舊舊的。\n但是我還是跟他進去電梯了。\n然後他就按了 22 樓。\n！！！！！！！！！ 22樓是什麼概念，大概一個是我已經有十幾年沒有到那麼高的樓層了。天啊這很不尋常吧，正常人一定覺得莫名其妙吧？！\n然後我就跟他進到22樓了\n22樓欸，222222222222222\u0026hellip;\u0026hellip;. 進去之後的樣子就真的像我以前補習的補習班大樓那樣，是以電梯為中心的一個ㄇ字型。 一出電梯之後，旁邊有的賣珠寶，有的賣服飾(一家一家的在各自的房間裡)，然後他就帶 我進去他們的......據點？裡面看起來也不是特別明亮。接著就有人出來接待啦，那個拉 我進去的還說什麼 ：經理，這是從台灣來這邊讀書的同學\n講了一些歡迎之類的話，然後接著他就叫我進去一個房間，我居然很聽話的就進去了\n叫我躺到一個床上，我也躺上去了\n然後那個房間的門就被關起來了\n！！！！ 等到幾秒鐘後他拿一個毛巾綁在我的額頭之上，然後開始劈哩啪啦跟我一直聊天似乎不想讓我有機會講其他話的時候，我發覺事態有點嚴重了，越想越不對勁。\n我開始假裝滑手機，然後正當他好像在準備，要把什麼東西塗到我額頭上的時候，我就說\n：呃不好意思，我同學跟我說他在樓下等我，我們要一起去趕車，我可能要走了\n要塗奇怪東西在我臉上的人\n：等一下喔我問一下經理\n然後最智障的地方在這裡\n經理就進來\n：蛤你要走了喔，可是你這樣就還沒體驗到我們的護膚欸，你是要搭幾點的車啊\n我想說，如果我這時候才打開手機看時間，然後掰一個時間有點太假了(真是智障都死到 臨頭了還管假不假)，然後我依稀記得大概的時間是九點多，所以我就\n：喔我們要搭9：50的車。\n經理\n：什麼九點五十，現在都十點多了\nGod damn!!!!!! 現在已經十點了，你K在跟我開玩笑吧。然後我打開手機螢幕，上面寫著 10：26，還看起來很像在對我微笑??\n我只好趕快改口說10：50。\n結果他還說什麼50分的車你現在下去也來不及之類的話，要我問問看我同學可不可以再等 一下，反正一臉不想讓我走。\n我就坐起來假裝在打字，心裡慌的要死，想說完蛋了，腦海還一直幻想出現我同學真的在 下面等我的畫面。\n最後我就直接站起來說不行，我同學已經等很久了，我真的要下去了。(他途中還問我等 我的是男孩子還是女孩子)，最後他們就看起來很失望的說好吧，而且還一直說這樣剛剛 那個人就沒辦法賺到錢了(我都嚇死了誰管你，而且我從小房間裡面出來之後那個人就不見了)\n出來之後還想說要不要走到21樓再坐電梯下去，會不會等一下被抓走，結果走到樓梯間， 看到那個陰暗恐怖像鬼屋的樓梯，直接打消念頭。還好後來安全的從那個恐怖的大樓下來，直接遠離他。\nEpilogue 一下來我就上百度查有沒有人發生過這樣的事情，結果居然還有專門報導這類事件的新聞。新聞說這些推銷員都會把你騙到一個小房間，然後開始幫你弄一些美容之類的東西，結束之後就會叫你要付錢，不然就是要辦卡，如果不從有些還有召喚壯漢把你團團圍住，還不准你報警!!!，損失金額從幾百到幾千人民幣不等(乘以5大概就是台幣)，目標主要是女森或是歪國遊客。\n22樓的夥伴們一定想說到手的肥羊就這樣飛了\n好吧我一定是個大傻逼，人太好還要幫人家賺業績。\n回去跟我一起去的的同學講\n ：天啊太恐怖了吧\n：你差點就回不來了欸\n：我之前也有遇過欸，可是我走到一半就跑掉了\n我：對啊我真是入虎穴\n：啊你有沒有得到虎子？\n：\u0026hellip;\u0026hellip;\u0026hellip;\n 回家後跟我的家人講\n我爸：你這樣很危險欸\n我姐：要是我碰到這種都直接不理他的\n我媽：你同學還比你聰明，走到一半就知道不對勁，結果你還跑到22樓還進去\n我姐：你的腎差一點就要被挖走了欸\n我媽：你這樣不行欸，很容易被騙，你以後會不會跟電視新聞上那種一樣被騙啊\n\u0026hellip;\u0026hellip; 還好我回來了，而且$$乖乖的在口袋 嗚嗚嗚我以後不要跟推銷員講話了\n我是87吧。\n",
    "ref": "/blog/strange/"
  },{
    "title": "About",
    "date": "",
    "description": "",
    "body": "Yuwei_tt About Me\n今年要邁向 24 歲。\n桃園人，在新竹待了四年，研一，邁向台北的第二年\n喜歡在街頭到處走，一台相機，一張地圖，就是一整天\n鍵盤敲久了，就忘了手寫的自然\n忘了從前，用雙手刻下的回憶，字字珠璣\n看著牆上的時鐘，滴答滴答的過去，害怕自己留不下什麼\n害怕曾經的深刻，都只是隨著身體的細胞，慢慢死去\n有太多特別，有趣，如果不好好記錄下來，那也，太對不起自己\n #Kpop : TWICE、IU、DAY6\n#Badminton : 快樂打羽球\n#Photogrrapth : 一腳踏入攝影的陷阱了，開闊了另一隻眼\n#ComputerScience\n",
    "ref": "/about/"
  },{
    "title": "哈爾濱 (一)",
    "date": "",
    "description": "哈爾濱 - 旅遊札記",
    "body": "2018，哈爾濱的六個星期\n一想到哈爾濱，白雪紛飛，零下的溫度總是不自覺的湧入腦海\n其實夏天的哈爾濱，也是有那麼一兩個禮拜，跟台灣一樣炎熱。一年一半時間都在大雪的東北，大部分都沒有裝上空調，因此一到炙熱的夏天，幾乎沒什麼躲避太陽的好去處。但是一旦進入到了八月初，氣溫就會坐上遊樂場邊的溜滑梯，慢慢地，不經意的從上頭滑落。\n受到俄羅斯的影響，不論是舊式老房屋，或是新建的大樓，哈爾濱的建築都蘊含著一股歐式的風情。不過可能環境和人還是影響很大，所以大概待了一個禮拜就開始習慣了，原本覺得的浪漫風情就消失殆盡XD。\n其實原本也沒想過會到哈爾濱，一開始來的時候，心情挺複雜的，特別是第一天到哈爾濱的飛機因為颱風延誤，到了哈工大宿舍的時候已經晚上九點多了，整頓好行李已經接近十二點。\n不像台灣隨處就有24小時營業的便利商店，哈爾濱大部分都是超市，10點鐘就會關燈休息，只有少數幾家會24小時營業。剛到哈爾濱人生地不熟，也不敢在大半夜亂跑，就忍著又渴又餓，還沒有網路可以跟家人報名平安，在百般無聊之際，只好躺上床鋪，闔上眼，等待早晨的陽光。\n若不是因為暑期交換，我想我一生中，可能都沒有機會，也沒有動機，飛到這麼偏北的哈爾濱遊歷，更別說是在這待上一個半月。生活在北緯44度的斜陽中，體驗東北的風情，走在歐式建築的校園中，絕對是一生難得的經驗以及回憶。\n",
    "ref": "/blog/harbin_1/"
  },{
    "title": "Contact",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
