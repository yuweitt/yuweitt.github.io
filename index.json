[{
    "title": "心得筆記",
    "date": "",
    "description": "《公司的品德》心得筆記",
    "body": "簡介 前一陣子讀了《公司的品德》這本書，其中詳細的介紹了許多上市櫃公司的案例，剖析其中的故事以及案例。這份筆記主要將各章節的重點節錄\n 公司的品格 案例1，誰是接班人？台積電的交棒難題  2009年，交棒四年的張忠謀重回總執行長 由於2008年的金融風暴，張忠謀不得不再次扛起責任。 基於企業永續經營的思維，歐美企業很早就建立接班人計劃，並且納入公司風險中。歐美的經營權和所有權是分開的。 台灣多是家天下，可能缺發經驗、沒有興趣、兄弟鬩牆 新光集團分裂\u0026raquo;新光金控、新光產檢、台新金控、新光化纖大台北銀行 以台塑集團為例，良好的接班典範(王永慶、王永在) 利用集團交叉持股\u0026raquo;永不分家 集體領導和漸進式交棒(五人決策小組\u0026raquo;七人決策小組) 比爾蓋茲「沒有王安電腦的策略錯誤，我今天只會是個數學家或是工程師」  以IBM為例，如何培訓接班人\n建立板凳計畫、師徒制、特別助理制(擔任其他區域總裁)\n每個員工都是為有潛力成為接班人，所有主管都有挖掘人才和培養部屬的責任。\n個案2，高階主管獎酬計畫，是刺激還是利誘  以宏碁電腦為例 2012年通過「高階主管薪酬管理準則」延遞支付獎金、若當時決策導致公司後期損失，公司有權向主管索回以支付之報酬。 以宏碁電腦前總經理─蘭奇為例 大量降低研發成本，使宏碁變成廉價的電腦品牌，淨利率只剩下2%~3%。   獎酬計畫可能造成經理人過度重視短期效益 弄饋缺失與會計師責任 總經理兼任董事減損董事會功能  宏碁電腦期間研發費用僅占營收0.1% ~ 0.2%，企業平均為1.3%~2.7%，蘋果為3%\n公司被掏空，簽證會計師難道不用負責任嗎?  會計師沒有你想像中獨立 內部記帳人員常常是老闆的心腹，容易受到老闆的指引，再加上會計師簽證業務也是很競爭的，要考慮到現實的飯碗問題。 快機師並不是如你想像的有能力 如果公司要造假，一定會做出一套完整的憑證，例如導入ERP以及廣設海外子公司，甚至是多層孫公司，孫孫公司海外關係人 會計師的專業性有限 如何認列投資商品的成本和收益，會計師不見得有足夠的金融知識  應該\n 提高會計師的獨立性 提高會計師的懲戒與其責任  案例3，企業分割，小股東任人宰割?  以2011年英業達公司為例，收購英華達，收購價為議價20% 英華達原為旗下手持裝置和科技繪圖的部門，於2000年切割獨立 母公司早在上市前，就以分散股權為由，出售持股  公司分割與股東權益  水平分割 和碩以及華碩的切割，和碩為代工，華碩為自有品牌 合資成立新公司 旗下部門由於市場競爭激烈，獲利不佳拖累公司，透過切割或出售或合併同類型公司，以達到市場規模經濟。 獨立部門，100%持有子公司 最常見也是最多的─圓剛科、大同   子公司透明度 股東權益的保障 特定人認購 子公司交易價的合理性  為什麼台灣上市櫃公司，喜歡分割旗下金雞母上市?  法令的規範或規避法令(反托拉斯法─壟斷) 希望能更專注於特定產業 公司原本主力趨於沒落，不希望拖累高成長部門  案例4，誰才是真正的老大？  以蔡萬才，說明藏鏡人─影子董事，不必負責任卻掌管公司 法人董事代表、糾纏不清的股權結構 金字塔股權結構、交叉持股、交叉表決權、財團法人與公益團體   廢除法人代表制 嚴格限制交叉持股和母子公司投票權 從嚴認定影子董事  案例5，一場荒謬的股東會─中石化經營權之爭  以中石化2012年6月苗栗股東大會為例，詮釋市場派以及公司派的公司爭奪權，荒謬的股東大會   少數股權控制整個公司 股東平等原則 現行法規的制度漏洞 更換股務代理僅需前一個月提出申請，並且董事會可以隨時決議變更議程，加上法院審理和事實認定往往曠日廢時，等到判決確立，往往是董監任期屆滿之時。 獨立董事成為控制公司的工具 應推動電子投票  游牧救援董事  在公司經營層有需求時，出任法律顧問，甚至跳下來擔任董事。除了運籌帷幄，也希望在短時間內解決問題。 從公司治理角度而言，顯得突兀。主要為了要驅除外敵，而公司的經營決策及長遠發展，都不會是關心的重點。 法人董事代表制，等於出錢雇用可能公司在幹嘛都不知道的人來擔任董事 傭金該怎麼算?  案例6，另類台灣奇蹟，台灣股東會亂象  小股東為紀念品因小失大 只要交付股東會通知書中附加的委託書   公司派持股不足，徵求委託書以鞏固經營元 透過徵求委託書取得公司經營權 市場派無法取得股東名冊，依法不得自行提供紀念品。  向法人投資者另行開價或予以承諾 像委託書徵求業者私下開出更好的條件     股東黃道吉日 希望開在同一天，這樣才不會有很多股東出席，省去麻煩 2012年限制一天只能有120家公司開立股東會   董監事最低持股比率要求 委託書之徵求與蒐購  不得以給付金錢或其他利益來換取委託書 不得為空白委託書 一人受兩人以上股東委託時，其代理之表決權不得超過發行股數的3%   紀念品發放的合理性 從電子投票看主管官員心態  案例7，什麼是合理的董監酬勞？以力晶科技為例  2007年底，力晶16為董監事合計領取7.48億 力晶自過去幾年業績下滑，銷貨收入降四成，盈餘衰退191% 引發眾人質疑是否合理   個別董監酬勞揭露 董監紅利合理評估 董監事的評鑑制度 薪酬委員會的獨立和強制性  台灣政府四大基金持股這麼多，為什麼不以股東名義要求上市公司推行公司治理 勞工退休基金，勞工保險基金，國民年金，公務人員退休撫卹基金\n以CalPERS為例，和台灣的公務員退撫基金類似\n 獨立性 投資以穩定為主要導向 缺乏核心標準  案例8，績優生也犯錯，從中華電信避險案看內部控制 案例9，全額連技法與累積投票制，從大毅科技事件談董監事選舉方式 案例10，犧牲「小我」完成「大我」，談大股東背信 案例11，砸大錢保股價，庫藏股面面觀 案例12，禿鷹與狼的鬧劇，亞洲化學 頻頻更換董座，2009年，惡意併購\n案例13，高獲利低配股的迷思，從TPK宸鴻談起 案例14，餐桌上的董事會，莊頭北工業啟示錄 案例15，政治利益與股東利益，孰者為重 2012年中華電信投資中華航空為例\n 長期配合政府政策 不務正業威脅本業 以中鋼為例，大量投資其他產業  案例16，帝國夢碎，股東買單─明基併購啟示錄 以明碁電通併購德國西門子公司為例\n台灣上市櫃公司董事長，會因為經營績效不佳而下台嗎? 台灣上基本很少\n 國營或政府控制，績效不佳只是幌子 公司經營不善，接近破產或明顯違法掏空 公司被市場派搶奪成功，兄弟鬩牆等  案例17，從國巨案台台灣的管理層收購 2011年，國巨董事長宣布由個人國際私募基金合組的敖睿股份有限公司，收購100%國巨股權，下市重整為例。\n案例18，公司的監督力量 以2010年，上市公司勝華，揚言提告摩根大通撰寫建議客戶減碼勝華股票為案例，終止與摩根大通其全球存託憑證承銷的相關業務，失去約當數億元新台幣的傭金。\n外部監督力量\n 商業銀行 專業投資機構 信用評等公司 市場機制  案例19，買殼與借殼上市  借殼上市規避監理  現金併購 股權交換   應給予殭屍企業的退場機制 介殼掛牌公司的監理 浮濫的現金增資與關係人交易  從絢爛到殞落，再到重生的故事─東隆五金\n案例20，用你的錢來爭奪經營權 以2003年中華開發金融控股公司，以及中華開發工業銀行為例\n案例21，是慈善公益還是慷股東之慨 以董事長夫人曾馨瑩鴻海捐贈台幣1億元為例\n怎麼樣可以掏空一間公司? 案例22，企業的社會責任 2009台塑的汙染為例\n 仁武廠區 柬埔寨 六輕石化 ",
    "ref": "/blog/book_company/"
  },{
    "title": "LLVM 雜記",
    "date": "",
    "description": "一些有關 LLVM 的小小筆記",
    "body": "簡介 算是在研究 LLVM 時，一邊學習一邊踩坑的小筆記，所以有點雜亂，之後有機會再好好整理。學習過程主要是希望可以用 Clang 編譯 CUDA code，並且利用 LLVM IR 對 Host side 的 Code 做一些變化。最一開始從網路上的一個 LLVM Project 開始 Trace Code，並且一邊修改一邊嘗試。\n LLVM CUDA OPENTUNER tags: CS Relevent Link nvcc-llvm-ir\nCUDAAdvisor\nDifferent Version Compatibility\nDynaMap\nGpuDrano Dynamic Analysis\nGPU Drano Static Analysis\nEnabling on-the-fly manipulations with LLVM IR code of CUDA sources\nLLVM Pass Slide (這個好像很讚)\nGood Intro to LLVM IR Pass\n一些之乎大神\n這個在講怎麼編譯\n在講 NVVM 讚\n這邊講了一下 CUDA 的一些限制，還不錯\nLLVM字典\n RAUW Replace All Uses With. Implement the replacement of one Value with another by iterating over its def/use chain and fixing up all of the pointers to point to the new value.  LLVM Install Build from source  Clone and version specified git clone https://github.com/llvm/llvm-project.git -b llvmorg-10.0.0 Follow Clang/LLVM Build clang and llvm cmake command cmake -DCMAKE_INSTALL_PREFIX=/usr/bin -DCMAKE_BUILD_TYPE=Release -D_GLIBCXX_USE_CXX11_ABI=0 -DLLVM_ENABLE_PROJECTS=clang -G \u0026quot;Unix Makefiles\u0026quot; ../llvm  Link with full path sudo ln -sf ~/llvm-project/build/bin/* /usr/bin/  Error while compilng LLVM $ -- Performing Test HAVE_GNU_POSIX_REGEX -- failed to compile 好像沒差???\n LLVM IR to executable 感覺還滿詳細的教學 CUDA 學習系列網址 Makefile\nssh -L 5906:127.0.0.1:5906 -N -l yuweitt 140.112.42.182 -p 607\nCompilation breakdown 這邊基本上就是利用 verbose 的 Flag，把整個 Flow 都印出來。但是有一個問題，就是我找不到 cicc，在 CUDA 的官方文件中，這個基本上是要用來完成 device code to ptx 的部分。 問題是在 cuda 的 binary 裡面並沒有看到這個 executable，所以也沒有辦法編譯。不過其實好像也不用用到 cicc，反正他只是要把 fatbinary 編出來，用 $fatbinary 就可以把他編出來了。\n➜ vectorAdd nvcc -dryrun --include-path=\u0026#34;../../common/inc\u0026#34; vectorAdd.cu $ gcc \u0026#34;vectorAdd.cu\u0026#34; \u0026gt; \u0026#34;8_vectorAdd.cpp1.ii\u0026#34; $ cicc -arch compute_30 --include_file_name \u0026#34;2_vectorAdd.fatbin.c\u0026#34; --orig_src_file_name \u0026#34;vectorAdd.cu\u0026#34; --gen_c_file_name \u0026#34;5_vectorAdd.cudafe1.c\u0026#34; --stub_file_name \u0026#34;5_vectorAdd.cudafe1.stub.c\u0026#34; \u0026#34;8_vectorAdd.cpp1.ii\u0026#34; -o \u0026#34;5_vectorAdd.ptx\u0026#34; $ ptxas -arch=sm_30 \u0026#34;5_vectorAdd.ptx\u0026#34; -o \u0026#34;9_vectorAdd.sm_30.cubin\u0026#34; $ fatbinary --create=\u0026#34;2_vectorAdd.fatbin\u0026#34; \u0026#34;--image=profile=sm_30,file=9_vectorAdd.sm_30.cubin\u0026#34; \u0026#34;--image=profile=compute_30,file=5_vectorAdd.ptx\u0026#34; --embedded-fatbin=\u0026#34;2_vectorAdd.fatbin.c\u0026#34; $ gcc \u0026#34;vectorAdd.cu\u0026#34; \u0026gt; \u0026#34;4_vectorAdd.cpp4.ii\u0026#34; $ cudafe++ --gen_c_file_name \u0026#34;5_vectorAdd.cudafe1.cpp\u0026#34; --stub_file_name \u0026#34;5_vectorAdd.cudafe1.stub.c\u0026#34; \u0026#34;4_vectorAdd.cpp4.ii\u0026#34; $ gcc -o \u0026#34;10_vectorAdd.o\u0026#34; \u0026#34;5_vectorAdd.cudafe1.cpp\u0026#34; $ nvlink --register-link-binaries=\u0026#34;6_a_dlink.reg.c\u0026#34; \u0026#34;10_vectorAdd.o\u0026#34; -o \u0026#34;11_a_dlink.sm_30.cubin\u0026#34; $ fatbinary --create=\u0026#34;7_a_dlink.fatbin\u0026#34; -link \u0026#34;--image=profile=sm_30,file=11_a_dlink.sm_30.cubin\u0026#34; --embedded-fatbin=\u0026#34;7_a_dlink.fatbin.c\u0026#34; $ gcc -DFATBINFILE=\u0026#34;\\\u0026#34;7_a_dlink.fatbin.c\\\u0026#34;\u0026#34; DREGISTERLINKBINARYFILE=\u0026#34;\\\u0026#34;6_a_dlink.reg.c\\\u0026#34;\u0026#34; -o \u0026#34;12_a_dlink.o\u0026#34; \u0026#34;/usr/local/cuda/bin/crt/link.stub\u0026#34; $ g++ -o \u0026#34;a.out\u0026#34; --start-group \u0026#34;12_a_dlink.o\u0026#34; \u0026#34;10_vectorAdd.o\u0026#34; Compilation command from clang verbose Link 單純利用 clang++ um.cu -o um --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread 編譯的時候，如果下 -v 的 verbose Command 可以看到他實際跑了哪些指令。在原本的指令中，沒有儲存 Intermediate，直接生成 object file，但是只要把原本的 -emib-obj 改成 -emit-llvm-bc，就可以了。然後 bc 一樣可以直接跑 LLVM 的 pass，最後可以編譯成功。\n跑 pass 的指令 opt -S -load /home/yuweitt/llvm-project/build/lib/CUDAMemPass.so -cudamem host.ll -o hosti.ll\nMakefile from CUDAAdvisor Link 從 CUDAAdvisor 找到他們的 Makefile，我改成我需要的形狀，但是目前也還不能編譯。\nCUDAAdvisor 這邊走的是一個 clang++ cc1 風格，解釋大概長這樣\nThe Clang compiler front-end has several additional Clang specific features which are not exposed through the GCC compatibility driver interface. The -cc1 argument indicates that the compiler front-end is to be used, and not the driver. The clang -cc1 functionality implements the core compiler functionality.\n他下了很多不同的 flag，這部分跟 clang++ 直接把 cuda file 編譯成 executable 的過程一樣，也有調用到 clang++ -cc1。這邊編譯遇到的問題是 undeclared identifier，這個感覺比較麻煩，因為明明有下-fcuda-include-gpubinary device.fatbin 這條，所以照理說會連結到已經編好的 cuda fatbinary 才對，這部分還要再研究一下。\num.cu:46:8: error: use of undeclared identifier cudaConfigureCall Myadd\u0026lt;\u0026lt;\u0026lt;numBlocks, blockSize\u0026gt;\u0026gt;\u0026gt;(N, x, y); ^ 1 error generated when compiling for host. CUA_Makefile:39: recipe for target \u0026#39;host.bc\u0026#39; failed My Makefile Link\nMakefile from Stackoverflow Link 這個 Makefile 是從 Stackoverflow 上面來的，該作者用的是 Power PC ??，但反正應該改成 x86_64 就可以了，只是不知道為什麼還是不能跑。\n這邊最後 link 部分是直接調用 NVIDIA 的 nvcc，反正無腦給他跑應該就會自己去啟動 driver，就沒有用到上面的 clang++ -cc1，不過現在問題就是遇到這個 error，找不到-lc++，我上網查也找不到太到-lc++這個 flag，可以想見它就是要 load c++ library，但是這樣下 flag 真的是對的嗎? 作者是說他可以跑，我再試試看。\nnvcc um.o um_dlink.o -o um -arch=sm_61 -lc++ /usr/bin/ld: cannot find -lc++ collect2: error: ld returned 1 exit status 如果把那個 flag 拿掉會變這樣，GG\nnvcc um.o um_dlink.o -o um -arch=sm_61 /usr/bin/ld: um.o: relocation R_X86_64_32 against symbol `_Z5MyaddiPfS_\u0026#39; can not be used when making a PIE object; recompile with -fPIC /usr/bin/ld: final link failed: Nonrepresentable section on output collect2: error: ld returned 1 exit status My github Makefile link\nCUDA 路徑  LD_LIBRARY_PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local CUDA_HOME export CUDA_HOME=/usr/local/cuda export PATH=$PATH:/usr/local/cuda/bin  CUDA 編譯學習   clang++ -c The -c flag is used to tell the compiler you don\u0026rsquo;t want to build a program (link together into an executable), just compile this particular file into an object file - typically producing a file called something.o or something.obj\n  -E Stop after the preprocessing stage; do not run the compiler proper. The output is in the form of preprocessed source code, which is sent to the standard output.\n  Stpes\n  # This generate um-cuda-nvptx64-nvidia-cuda-sm_61.s and um.s $ clang++ -S um.cu --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread # This generate cuda device object file $ ptxas -m64 -O0 --gpu-name sm_61 --output-file um-cuda.o um-cuda-nvptx64-nvidia-cuda-sm_61.s # This generate cuda fatbinary $ fatbinary -64 --create um-cuda.fatbin --image=profile=sm_61,file=um-cuda.o --image=profile=compute_61,file=um-cuda-nvptx64-nvidia-cuda-sm_61.s $ llc \u0026lt; new.ll \u0026gt; new.s CUDA 的 Comiple Flow\n這個是 NVIDIA 的官方文件，講述 NVVM 還有 LLVM IR 的東西。\n NVVM IR 和 LLVM IR Technically speaking, NVVM IR is LLVM IR with a set of rules, restrictions, and conventions, plus a set of supported intrinsic functions. A program specified in NVVM IR is always a legal LLVM program. A legal LLVM program may not be a legal NVVM program.  Command clang++ um.cu -o um --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread\nclang++ --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lcuda -lrt -pthread -lcudart um.o um-cuda.ptx.o -o um 會有這個 error，加入 -lcudart 就可以解決沒有 reference 的問題，但是 incompatible 還是沒有辦法解決。\n How to write a LLVM Pass Example pass \u0026ldquo;Hello.cpp\u0026rdquo; under ~/llvm-project/llvm/lib/Transformation/. The correspond .so file will be genereated under ~/llvm-project/build/lib/ after rebuild.\n$clang `llvm-config --cxxflags` -Wl,-znodelete \\ -fno-rtti -fPIC -shared cuda_mem.cpp \\ -o CUDAMem.so `llvm-config --ldflags`  Run my LLVM pass $ opt -load lib/CUDAMemPass.so -cudamem \u0026lt; ~/cuda/um/um.ll \u0026gt; /dev/null  Understanding DynaMap 這邊先來看一下 Module, Function, Basic Block 的關係\n LLVMContext Important class for using LLVM in a threaded context Manage core \u0026ldquo;global\u0026rdquo; data of LLVM\u0026rsquo;s core infrastructure, including the type and constant uniquing tables  Peek into um.ll We see cudaMallocManaged\nModule.h iterator begin() { return FunctionList.begin(); } named_metadata_iterator named_metadata_begin() { return NamedMDList.begin(); } Get MDnode from module for (auto named_meta = module-\u0026gt;named_metadata_begin(); named_meta != module-\u0026gt;named_metadata_end(); named_meta++) for (auto op = named_meta-\u0026gt;op_begin(); op != named_meta-\u0026gt;op_end(); op++) // This is not working NamedMDListType (ilist\u0026lt;NamedMDNode\u0026gt;) Define in llvm/Module.h ilist\u0026lt;T\u0026gt;是LLVM中自定義的其中一種 Container，其實就和 STL 的 List 很像，但是做了一些改變以符合 LLVM 內部需求。詳細請見 User Manual 所以總的來說，他就是一個 List 裡面存一堆 NamedMDNode\nNamedMDNode A tuple of MDNodes. Despite its name, a NamedMDNode isn\u0026rsquo;t itself an MDNode. It is illegal for a NamedMDNode to appear as an operand of an MDNode. 這邊暫時不太懂他在幹嘛 :::info A NamedMDNode looks like this: !named = !{!0, !1} An MDNode looks like this: !0 = !{!1, i32 0, i32* @global} :::\nNamedMDNode *node = module-\u0026gt;getNamedMetadata(MetaName); // 大部分的操作好像都長這樣，可是我要怎麼拿到 MDNode呢 MDNode Metadata nodes can be uniqued, like constants, or distinct. Temporary metadata nodes (with full support for RAUW) can be used to delay uniquing until forward references are known. The basic metadata node is an MDTuple. 要怎麼使用 MDNode 呢，請看 MDNode\nMDNode *getLoopID() const; // Return the llvm.loop loop id metadata node for this loop if it is present. Metadata Root of the metadata hierarchy. This is a root class for typeless data in the IR. 也許我們把 Metadata 搞懂，就可以知道這一系列在幹嘛 Here comes the explaination -\u0026gt; link :::info\n One example application of metadata is source-level debug information.  class Metadata { //這三個不知道在幹嘛 enum StorageType { Uniqued, Distinct, Temporary }; unsigned char Storage : 7; unsigned char SubclassData1 : 1; unsigned short SubclassData16 = 0; unsigned SubclassData32 = 0; IRBuilder Literally, build LLVM IR.\nProblem 好像要先人工分析一些 IR 的資訊，才知道 Pass 要怎麼寫，所以可能要先看懂一些 Label (Function 的)，這樣才知道 Pass 要寫啥。\n什麼時候用 Metadata，Functin Name???\nNaming convention ???\n  Compile Cuda with clang Generate bc and opt pass clang -emit-llvm um.cu -c -o hello.bc\nCommand clang++ um.cu -o um --cuda-gpu-arch=sm_61 -L /usr/local/cuda/lib64/ -lcudart_static -ldl -lrt -pthread -save-temps\n cudart : cuda run time dl : This is the interface to the dynamic loader, which provides a client program with ability to do things such as explicitly load other libraries, lookup symbols within, etc.  cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=clang -G \u0026quot;Unix Makefiles\u0026quot; ../llvm \nHow to specify compute capability What is cui file ??? with cuda docker and clang-12\n\u0026lt;built-in\u0026gt;:1:10: fatal error: \u0026#39;__clang_cuda_runtime_wrapper.h\u0026#39; file not found #include \u0026#34;__clang_cuda_runtime_wrapper.h\u0026#34; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1 error generated when compiling for sm_62. Bad, docker seems to be the root of devil.\ngpucc: An Open-Source GPGPU Compiler\nGPU Compute Capability\n llc : The llc command compiles LLVM source inputs into assembly language for a specified architecture. -g flag : Generate complete debug info.    Manipualte CUDA UM Advanced Advice __host__ ​cudaError_t cudaMemAdvise \\ ( const void* devPtr, size_t count,\\ cudaMemoryAdvise advice, int device ) 所以會用到的值應該是 1、3、5 這三個。 NVIDIA Reference\n Default cudaMemAdviseSetReadMostly cudaMemAdviseSetPreferredLocation cudaMemAdviseSetAccessedBy   cudaMemAdvise(a, Size∗Size∗sizeof(float), cudaMemAdviseSetReadMostly, 0)\nIn LLVM IR Compile 出來會變成\ndeclare dso_local i32 @cudaMemAdvise(i8*, i64, i32, i32) #1 // 這個我有 %156 = load %struct.XYZ*, %struct.XYZ** %26, align 8 %157 = bitcast %struct.XYZ* %156 to i8* // %158 = load i32, i32* %19, align 4 %159 = sext i32 %158 to i64 %160 = invoke i32 @cudaMemAdvise(i8* %157, i64 %159, i32 1, i32 0) to label %161 unwind label %137 我插的，但是不能跑，會有 cuda error\ndeclare dso_local i32 @cudaMemAdvise(i8*, i64, i32, i32) %72 = load %struct.XYZ*, %struct.XYZ** %26, align 8 %73 = bitcast %struct.XYZ* %72 to i8* %74 = call i32 @cudaMemAdvise(i8* %73, i64 4096, i32 0, i32 0) Distance = 5\n265: ; preds = %261 %266 = getelementptr inbounds %struct.Params, %struct.Params* %11, i32 0, i32 1 %267 = load i32, i32* %266, align 4 %268 = getelementptr inbounds %struct.Params, %struct.Params* %11, i32 0, i32 1 %269 = load i32, i32* %268, align 4 %270 = mul nsw i32 %267, %269 %271 = load i32, i32* %35, align 4 %272 = icmp sle i32 %270, %271 br i1 %272, label %273, label %278 273: ; preds = %265 %274 = load %struct.XYZ*, %struct.XYZ** %26, align 8 %275 = bitcast %struct.XYZ* %274 to i8* %276 = call i32 @cudaMemPrefetchAsync(i8* %275, i64 512, i32 0, %struct.CUstream_st* null) %277 = call i32 @cudaMemAdvise(i8* %275, i64 512, i32 0, i32 0) br label %278  Manipulate CUDA Prefetch LLVM Manual Book\n因為我要放進去一個 Null Pointer，首先我先想辦法抓到 Struct 的 Type 結果我發現 LLVM 有很多 Type 這邊可以看到，StructType 就是其中之一，而其中就有 static function 可以根據你的 struct Name 拿到相對應的 Struct Type。\n這邊要注意的一點，就是我用的是 LLVM 10.0，而現在最新版的 Docutment 已經到 LLVM 14.0，最新版的 API 長這樣，基本上很易用，你只要把 Struct 的字串跟 Context 一起丟進去就可以了。\nstatic StructType * StructType::getTypeByName (LLVMContext \u0026amp;C, StringRef Name) 但是 LLVM 10.0的不行，10.0 的長這樣，而且是定義在 Module 的 class 裡面\nStructType* Module::getTypeByName (StringRef Name) const 至於要找之前的 Document 的話，我是打 LLVM 10.0 Doxygen，然後去下載他的 Docs，連結大概會長這樣，然後再去下載裡面的 llvm doxygen，解壓縮後就會有一堆 HTML 可以看。\n整體來說會長這樣\nStructType* CUstream_struct = module-\u0026gt;getTypeByName(\u0026#34;struct.CUstream_st\u0026#34;); // Check not null if(CUstream_struct) errs() \u0026lt;\u0026lt; \u0026#34;\\t CUstream struct : \u0026#34; \u0026lt;\u0026lt; CUstream_struct-\u0026gt;getStructName().str() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // Create null pointer Constant* CU_stream = ConstantStruct::getNullValue(CUstream_struct); 但是目前他的 IR 出來不是 Null，而是 Zero Initializer，感覺有鬼，哭啊。\n有一個想法是，先轉成 PointerType，然後再用Constant* ConstantPointerNull::get(PointerType) 這個函數拿到 null struct Pointer。但是很顯然我用dyn_cast的時候就出事了，轉出來是 nullptr。具體來說是這樣，還在研究。\nStructType* CUstream_struct = module-\u0026gt;getTypeByName(\u0026#34;struct.CUstream_st\u0026#34;); PointerType* CUstream_pointer = dyn_cast\u0026lt;PointerType\u0026gt;(CUstream_struct); // 這邊就不會 Print 東西出來了 if(CUstream_pointer) errs() \u0026lt;\u0026lt; \u0026#34;\\t CUstream pointer : \u0026#34; \u0026lt;\u0026lt; CUstream_pointer-\u0026gt;getElementType()-\u0026gt;getStructName().str() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // Segmentation Fault ConstantPointerNull* CU_stream_null = ConstantPointerNull::get(CUstream_pointer); 然後我上 StackOverflow 上面問，沒有人要裡我，哭啊 結果後來發現其實很簡單，不用 Cast 過去，PointerType Class 本身就有 static PointerType* get (Type *ElementType, unsigned AddressSpace)，所以 OK 的。 結論 - Nonintializer 的確不行\nStructType* CUstream_struct = module-\u0026gt;getTypeByName(\u0026#34;struct.CUstream_st\u0026#34;); ConstantPointerNull* CU_stream_null = ConstantPointerNull::get(PointerType::get(CUstream_struct, 0)); // 直接 bitcast Value* ir_ptr = builder.CreateBitCast(val, Type::getInt8PtrTy(context)); // Generate cuda prefetch instruction CallInst *MI = builder.CreateCall(cuda_prefetch_func, args); 愛情你比我想的閣較偉大 LLVM比我想的閣較複雜@@\n遇到的問題 現在 opt 跑完 Pass ，但是 IR 沒有改變，不知道是不是 opt 的用法\nInstruction does not dominate all uses (用第一個 Instruction 的話) Basic Block in function \u0026lsquo;main\u0026rsquo; does not have terminator! (用 BasicBlock 的話) Instruction referencing instruction not embedded in a basic block! (用 Context 的話)\n結論 排除以上困難，已經可以插入了 Prefetch，用 diff 看兩個 .ll 檔案 跑的指令 : opt -S -load lib/CUDAMemPass.so -cudamem ~/cuda/um/um.ll -o ~/cuda/um/new.ll \n Maybe relevent Paper\n現在遇到的一些困難是\n 這些 register 要怎麼拿到 ?? 還是要自己 Create ?? 我的 Function Callee 要放什麼 ?? 我怎麼知道有哪些 address 是要 prefetch 的 我想要知道之前 Prefetching 都是怎麼做的，利用Emulation ?? 還是 Cuda 我在 Auto-tune 的時候，是不是應該加上一些 Heuristic，還是完全自動，會不會無法收斂 GPU Page 有哪些東西可以改動，可是 Prefetch 是不是就會跟 Page Replacement 難以獨立 如果是會互相影響，是不是 Focus 一個做就好 ?? Granularity 要怎麼設會比較好?? 不同的 Optimization 之間，要一起做嗎???  想法\n 我可以知道 cudaMallocManage，那我應該就可以操控?? 我可以知道 Launch，那我也可以操控  看了一下 DynaDrano 以及其他的方法，大部分都是會寫 cu 的 Code，然後利用 LLVM Pass 把 Instrument 插進去。\n這個是從 CUDA 的 PTX 官方 Manual 上面拿下來的\n圖片太大了，有點礙眼，要看自己點進去\nCUDA Prefetch API\ncudaMemPrefetchAsync in LLVM IR 我現在可以拿到 Prefetch 的 Declaration 了 但是參數可能是一個問題\n目前可以做到這樣\n// %9 = alloca float*, align 8 // %16 = bitcast float** %9 to i8** // %20 = load i8*, i8** %16, align 8, !tbaa !7 // %21 = call i32 @cudaMemPrefetchAsync(i8* %20, i64 4096, i32 0, %struct.CUstream_st* null) IntegerType* int_type32 = IntegerType::get(context, 32); IntegerType* int_type64 = IntegerType::get(context, 64); ConstantInt* device_id = ConstantInt::get(int_type32, 0, false); ConstantInt* alloca_size = ConstantInt::get(int_type64, 4096, false); Value* args[] = {alloca_size, device_id}; builder.CreateCall(cuda_prefetch_func, args); 但是我要想辦法\n 生出 x 的位置 生出 struct.CUstream_st 的 null pointer  圖片\nWhat Next ???\n先看每個 Instruction 可以幹嘛\nfor (BasicBlock \u0026amp;BB : F) { for (Instruction \u0026amp;inst : BB) { if(inst.getOpcode() == Instruction::Call || inst.getOpcode() == Instruction::Invoke) { // errs() \u0026lt;\u0026lt; \u0026#34;\\\\n callinst =\u0026gt; \u0026#34; \u0026lt;\u0026lt; inst \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; // Instruction* I = \u0026amp;(inst); // errs() \u0026lt;\u0026lt; \u0026#34;\\\\n callinst =\u0026gt; \u0026#34; \u0026lt;\u0026lt; inst.getOpcodeName() \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; if (isa\u0026lt;CallInst\u0026gt;(\u0026amp;inst)) { Function *func = cast\u0026lt;CallInst\u0026gt;(\u0026amp;inst)-\u0026gt;getCalledFunction(); val = cast\u0026lt;CallInst\u0026gt;(\u0026amp;inst)-\u0026gt;getArgOperand(0); if(func) { StringRef fname = func-\u0026gt;getName(); if(fname == \u0026#34;cudaMallocManaged\u0026#34;) { errs() \u0026lt;\u0026lt; \u0026#34;\\\\t Function Name : \u0026#34; \u0026lt;\u0026lt; fname \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; errs() \u0026lt;\u0026lt; \u0026#34;\\\\n callinst =\u0026gt; \u0026#34; \u0026lt;\u0026lt; inst \u0026lt;\u0026lt; \u0026#34;\\\\n\u0026#34;; } } } } } } 什麼是 LLVM Instrinsic ??? Intrinsic函數是編譯器內建的函數，由編譯器提供，類似於內聯函數。但與內聯函數不同的是，因為Intrinsic函數是編譯器提供，而編譯器與硬件架構聯繫緊密，因此編譯器知道如何利用硬件能力以最優的方式實現這些功能\n研究一下其他人的 Call 都做了哪些事情 Tutorial 好像應該先 Initialize Load\nLoadInst *Load2 = Builder.CreateLoad(IntegerType::getInt32Ty(CTX), Var); Value *Inc2 = Builder.CreateAdd(Builder.getInt32(1), Load2); Builder.CreateStore(Inc2, Var); 別人的研究呢 ?? XPlacer 用的是 Rose Source to source 的方式改動，但以 Instrumentation 來說，我覺得根本就是差不多的東西。\nIn contrast to CudaAdvisor, XPlacer instruments source code. On one side, instrumented binary code typically runs faster because the instrumentation can be added to an optimized binary, whereas source-level construmentation often poses an obstacle to compile-time code optimization. On the other side, instrumenting source code offers better portability across CUDA versions and is easier to understand for programmers not familiar with low-level details. XPlacer’s function level instrumentation can be more easily customized through pragmas\nLLVM Loop Prefetch Scalar Evolution（SCEV）是編譯器中對於變量進行分析的一個非常有用並且強大的 Library，當然通常情況下只是對於Loop 中 int類型的變量進行分析。本文主要是介紹Scalar Evolution在LLVM中的使用。\nSCEV是LLVM中一個很重要的analysis pass。所謂的analysis pass就是這個pass只是做分析工作，並不會修改 IR Code。很多重要的優化 pass 都有使用SCEV的結果，比如說循環變量簡化（IndVars）， Loop Strength Reduce(LSR)，（Vectorizer）。 Ref\n",
    "ref": "/blog/llvm/"
  },{
    "title": "攝影。初",
    "date": "",
    "description": "第一次，被親手按下快門的照片，深深的驚豔",
    "body": "如果說哪件事情，深深改變了我的生活，那毫無疑問的，就是攝影\n",
    "ref": "/blog/conver/"
  },{
    "title": "哈爾濱驚魂記",
    "date": "",
    "description": "帶著貓咪的好奇心，單眼相機的一隻眼睛，踏上一個人的旅程，居然在虎口前驚險逃出??",
    "body": "越想越不對勁 Intro  2018年暑假的時候，來到了哈爾濱交換\n  那天，是八月底，回台灣前的兩天\n一直嚮往可以去爬長白山或是黃山，最後卻未果\n失望無奈之下，在那天小夥伴們還未甦醒之時\n獨自一人搭著地鐵在哈爾濱的市區亂晃\n prologue 事件發生在哈爾濱地鐵博物館站，秋林百貨附近，某個人來人往的十字路口。這個十字路口有點大，十字路口的每一個角落都有一棟百貨公司。由於人生地不熟，就在人來人往，川流不息的四個百貨公司角落亂晃。 當我顧著拍照的時候，一不小心一腳踩進一坑水裡面。 一個大媽在我踩到水之前提醒我小心有水坑(雖然我還是踩進去了)，我還想說哇人這麼好 ，還會關心路人。\n接著他就開始講話了：\n帥哥，我們現在有一個活動，可以體驗皮膚保養品的活動，因為我們現在在促銷階段，也是免費的，我就是負責這一方面，所以如果你來的話也可以幫我達成一點業績。\n大意大概是這樣，可能他那時候講的比較委婉。一來我是那種喜歡聽別人講廢話的人，常 常跟路上傳教的人講話，二來想說百貨公司都是很明亮開闊的空間，應該只是一下下可能拿個宣傳就沒事了。\n所以，我就答應他了。\n白癡\n然後他看我說好，就說要帶我走去他們的專櫃，還一直跟我聊一些什麼你是哪裡人啊，如 果之後你覺得好用再幫我們推銷一下啊之類的。一直到走進大樓之後我才開始發覺好像有點怪怪的。\n進去的大樓完全不是百貨公司，而比較像是以前補習班的那種大樓，一樓進去只有電梯， 而且都暗暗的，有點破破舊舊的。\n但是我還是跟他進去電梯了。\n然後他就按了 22 樓。\n！！！！！！！！！ 22樓是什麼概念，大概一個是我已經有十幾年沒有到那麼高的樓層了。天啊這很不尋常吧，正常人一定覺得莫名其妙吧？！\n然後我就跟他進到22樓了\n22樓欸，222222222222222\u0026hellip;\u0026hellip;. 進去之後的樣子就真的像我以前補習的補習班大樓那樣，是以電梯為中心的一個ㄇ字型。 一出電梯之後，旁邊有的賣珠寶，有的賣服飾(一家一家的在各自的房間裡)，然後他就帶 我進去他們的......據點？裡面看起來也不是特別明亮。接著就有人出來接待啦，那個拉 我進去的還說什麼 ：經理，這是從台灣來這邊讀書的同學\n講了一些歡迎之類的話，然後接著他就叫我進去一個房間，我居然很聽話的就進去了\n叫我躺到一個床上，我也躺上去了\n然後那個房間的門就被關起來了\n！！！！ 等到幾秒鐘後他拿一個毛巾綁在我的額頭之上，然後開始劈哩啪啦跟我一直聊天似乎不想讓我有機會講其他話的時候，我發覺事態有點嚴重了，越想越不對勁。\n我開始假裝滑手機，然後正當他好像在準備，要把什麼東西塗到我額頭上的時候，我就說\n：呃不好意思，我同學跟我說他在樓下等我，我們要一起去趕車，我可能要走了\n要塗奇怪東西在我臉上的人\n：等一下喔我問一下經理\n然後最智障的地方在這裡\n經理就進來\n：蛤你要走了喔，可是你這樣就還沒體驗到我們的護膚欸，你是要搭幾點的車啊\n我想說，如果我這時候才打開手機看時間，然後掰一個時間有點太假了(真是智障都死到 臨頭了還管假不假)，然後我依稀記得大概的時間是九點多，所以我就\n：喔我們要搭9：50的車。\n經理\n：什麼九點五十，現在都十點多了\nGod damn!!!!!! 現在已經十點了，你K在跟我開玩笑吧。然後我打開手機螢幕，上面寫著 10：26，還看起來很像在對我微笑??\n我只好趕快改口說10：50。\n結果他還說什麼50分的車你現在下去也來不及之類的話，要我問問看我同學可不可以再等 一下，反正一臉不想讓我走。\n我就坐起來假裝在打字，心裡慌的要死，想說完蛋了，腦海還一直幻想出現我同學真的在 下面等我的畫面。\n最後我就直接站起來說不行，我同學已經等很久了，我真的要下去了。(他途中還問我等 我的是男孩子還是女孩子)，最後他們就看起來很失望的說好吧，而且還一直說這樣剛剛 那個人就沒辦法賺到錢了(我都嚇死了誰管你，而且我從小房間裡面出來之後那個人就不見了)\n出來之後還想說要不要走到21樓再坐電梯下去，會不會等一下被抓走，結果走到樓梯間， 看到那個陰暗恐怖像鬼屋的樓梯，直接打消念頭。還好後來安全的從那個恐怖的大樓下來，直接遠離他。\nEpilogue 一下來我就上百度查有沒有人發生過這樣的事情，結果居然還有專門報導這類事件的新聞。新聞說這些推銷員都會把你騙到一個小房間，然後開始幫你弄一些美容之類的東西，結束之後就會叫你要付錢，不然就是要辦卡，如果不從有些還有召喚壯漢把你團團圍住，還不准你報警!!!，損失金額從幾百到幾千人民幣不等(乘以5大概就是台幣)，目標主要是女森或是歪國遊客。\n22樓的夥伴們一定想說到手的肥羊就這樣飛了\n好吧我一定是個大傻逼，人太好還要幫人家賺業績。\n回去跟我一起去的的同學講\n ：天啊太恐怖了吧\n：你差點就回不來了欸\n：我之前也有遇過欸，可是我走到一半就跑掉了\n我：對啊我真是入虎穴\n：啊你有沒有得到虎子？\n：\u0026hellip;\u0026hellip;\u0026hellip;\n 回家後跟我的家人講\n我爸：你這樣很危險欸\n我姐：要是我碰到這種都直接不理他的\n我媽：你同學還比你聰明，走到一半就知道不對勁，結果你還跑到22樓還進去\n我姐：你的腎差一點就要被挖走了欸\n我媽：你這樣不行欸，很容易被騙，你以後會不會跟電視新聞上那種一樣被騙啊\n\u0026hellip;\u0026hellip; 還好我回來了，而且$$乖乖的在口袋 嗚嗚嗚我以後不要跟推銷員講話了\n我是87吧。\n",
    "ref": "/blog/strange/"
  },{
    "title": "About",
    "date": "",
    "description": "",
    "body": "Yuwei_tt About Me\n今年要邁向 24 歲。\n桃園人，在新竹待了四年，研一，邁向台北的第二年\n喜歡在街頭到處走，一台相機，一張地圖，就是一整天\n鍵盤敲久了，就忘了手寫的自然\n忘了從前，用雙手刻下的回憶，字字珠璣\n看著牆上的時鐘，滴答滴答的過去，害怕自己留不下什麼\n害怕曾經的深刻，都只是隨著身體的細胞，慢慢死去\n有太多特別，有趣，如果不好好記錄下來，那也，太對不起自己\n #Kpop : TWICE、IU、DAY6\n#Badminton : 快樂打羽球\n#Photogrrapth : 一腳踏入攝影的陷阱了，開闊了另一隻眼\n#ComputerScience\n",
    "ref": "/about/"
  },{
    "title": "哈爾濱 (一)",
    "date": "",
    "description": "哈爾濱 - 旅遊札記",
    "body": "2018，哈爾濱的六個星期\n一想到哈爾濱，白雪紛飛，零下的溫度總是不自覺的湧入腦海\n其實夏天的哈爾濱，也是有那麼一兩個禮拜，跟台灣一樣炎熱。一年一半時間都在大雪的東北，大部分都沒有裝上空調，因此一到炙熱的夏天，幾乎沒什麼躲避太陽的好去處。但是一旦進入到了八月初，氣溫就會坐上遊樂場邊的溜滑梯，慢慢地，不經意的從上頭滑落。\n受到俄羅斯的影響，不論是舊式老房屋，或是新建的大樓，哈爾濱的建築都蘊含著一股歐式的風情。不過可能環境和人還是影響很大，所以大概待了一個禮拜就開始習慣了，原本覺得的浪漫風情就消失殆盡XD。\n其實原本也沒想過會到哈爾濱，一開始來的時候，心情挺複雜的，特別是第一天到哈爾濱的飛機因為颱風延誤，到了哈工大宿舍的時候已經晚上九點多了，整頓好行李已經接近十二點。\n不像台灣隨處就有24小時營業的便利商店，哈爾濱大部分都是超市，10點鐘就會關燈休息，只有少數幾家會24小時營業。剛到哈爾濱人生地不熟，也不敢在大半夜亂跑，就忍著又渴又餓，還沒有網路可以跟家人報名平安，在百般無聊之際，只好躺上床鋪，闔上眼，等待早晨的陽光。\n若不是因為暑期交換，我想我一生中，可能都沒有機會，也沒有動機，飛到這麼偏北的哈爾濱遊歷，更別說是在這待上一個半月。生活在北緯44度的斜陽中，體驗東北的風情，走在歐式建築的校園中，絕對是一生難得的經驗以及回憶。\n",
    "ref": "/blog/harbin_1/"
  },{
    "title": "Contact",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
